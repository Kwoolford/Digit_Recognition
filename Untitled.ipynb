{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5130e8e1-74b1-44c0-9709-d84a05379661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is practice for convoluted neural networks\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed75c56a-2b05-4aac-9dbc-0957aca8a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Preparing the data for the model\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"ylecun/mnist\")\n",
    "train_loader = torch.utils.data.DataLoader(ds, batch_size=64, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(ds, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd6022a-4d1d-49c8-a0dc-62d19ab3bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Creating the Validator\n",
    "def validate(model, train_loader, val_loader):\n",
    "    # Loops through the training and validation sets\n",
    "    for name, loader in [('train', train_loader),('val', val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Disable gradient computation since we are only doing inference\n",
    "        with torch.no_grad()\n",
    "\n",
    "            # Loops through each image in the train + val sets\n",
    "            for imgs, labels in loader:\n",
    "\n",
    "            # Sends the images and labels to the appropriate device (GPU or CPU)\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "\n",
    "            # Passes the images through the model to get predicted values\n",
    "            outputs = model(imgs)\n",
    "\n",
    "            # Retrieves the index of Maximum probability for each vector of predictions\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "\n",
    "            # Updates the running total of samples and correct predictions\n",
    "            total += labels.shape[0]\n",
    "            correct += int((predicted == labels).sum())\n",
    "\n",
    "        # Calculate and prints the accuracy for the current dataset\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d445b5da-5a68-49a0-bac3-356306bd6665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Creating the Residual Block in the Neural Network\n",
    "class ResBlock(nn.module):\n",
    "\n",
    "    # Initializing the class\n",
    "    def __init__(self, n_chans):\n",
    "        # Making sure the submodule has access to everything\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        # Creating the convolution that will be applied to the image during its pass\n",
    "        self.conv = nn.Conv2d(1,n_chans,kernel_size=2,padding=1,bias=False)\n",
    "\n",
    "        # Normalizes the mean and standard deviation of the batch\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "\n",
    "        # Initializing the weights of the convolutional layer\n",
    "        # Kaiming_Normal Makes weights follow a normal distribution with a mean of 0,\n",
    "        # and a standard deviation that depends on the number of input units\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight, nonlinearity='relu')\n",
    "\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "\n",
    "    # Defining the forward pass of the models, which dictates how data moves through the model\n",
    "    def forward(self, x):\n",
    "        # Applies the convolutional layer to the input\n",
    "        out = self.conv(x)\n",
    "\n",
    "        # Applies the batch normalization layer to the input\n",
    "        out = self.batch_norm(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "536dde15-9627-43c3-8242-b0c43d11adc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (2516164345.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[22], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    class ResBlock(nn.module)\u001b[0m\n\u001b[1;37m                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Creating the residual model\n",
    "class ResNet(nn.module):\n",
    "    # Initializing the variables in the class\n",
    "    def __init__(self, n_chans1=__, n_blocks=10):\n",
    "        # Important initialization paramer I keep forgetting\n",
    "        super().__init__()\n",
    "\n",
    "        # Initializes the amount of channels to be input/output parameters for the models\n",
    "        self.n_chans1 = n_chans1\n",
    "\n",
    "        # Creating the convolution to \n",
    "        self.conv = nn.Conv2d(1, n_chans1, kernel_size=1, padding=1, bias=False)\n",
    "\n",
    "        self.resblocks = nn.Sequential(\n",
    "            *[n_blocks * ]\n",
    "        )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4923c815-eede-4221-a08f-4904b649ce00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (60000, 2), 'test': (10000, 2)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = ds['train'][0]\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "647b7696-4ab8-4ef8-b61c-e9537e242e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAACzBVBJJwAO9dnp/wm8damu6Dw5dRjGf9IKw/+hkVPffCnWNJa7XVNV0Kxa1hErrNe/M2cnYqgElsAHpjkc1wlAODkV694W8c654t8M6n4TuvEctrrFw0cun3c0/lq+3AMJcDK5AyOeTkd+fPvGFn4gsvEtzF4m89tUG1ZJJjuMgUBVYN/EMKOe9YVXtK0bUtdvVs9LsZ7y4YgbIULYycZPoPc8V6lpfwh0/w7p66z8RdXj0y2z8llC4aWQ+mRn8lz9RXPfE3x1pvi46TYaPZTQadpMJghluWDSyrhQM9SMBe5Oc5NcBV7Tda1XRZJJNK1O8sXkG12tZ2iLD0JUjNQ3l9eahN517dT3MvTfNIXb16n6mq9Ff/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA90lEQVR4AWNgGMyAWUhIqK5jvdSy/9/rQe5kgTlWjs3KRiAYxHsyKfDzxYMgFiOIAALDvfwQBsO/pK8Mz97fhPLAlNDtvyBwbNv3j8jCUHbAnOy/f89yM2jPwiLJwMc4628UqgQTnPvp/0eGFAQXLg5lcO/764YuhuArf3y4IAfmfoQwlBX44e/fckkMYaiA7q6/f6dJ45IViP3zdzcuSQaGn39/OkBl4WEL4euFmLIwXDuETav6lKfAIPy1DYucRNFdUPCe9MOUE3e6CpI6FogZSEKrwbFyOIATQ5v5mkcgXV9auVGlwK4NDGRguL75b88HVDla8QBFF16ADQA8sQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6603e16a-4162-4f31-8d35-783411be29a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
