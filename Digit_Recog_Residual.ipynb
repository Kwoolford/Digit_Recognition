{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5130e8e1-74b1-44c0-9709-d84a05379661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is practice for convoluted neural networks\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed75c56a-2b05-4aac-9dbc-0957aca8a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Preparing the data for the model\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"ylecun/mnist\")\n",
    "train_loader = torch.utils.data.DataLoader(ds, batch_size=64, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(ds, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd6022a-4d1d-49c8-a0dc-62d19ab3bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Creating the Validator\n",
    "def validate(model, train_loader, val_loader):\n",
    "    # Loops through the training and validation sets\n",
    "    for name, loader in [('train', train_loader),('val', val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Disable gradient computation since we are only doing inference\n",
    "        with torch.no_grad()\n",
    "\n",
    "            # Loops through each image in the train + val sets\n",
    "            for imgs, labels in loader:\n",
    "\n",
    "            # Sends the images and labels to the appropriate device (GPU or CPU)\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "\n",
    "            # Passes the images through the model to get predicted values\n",
    "            outputs = model(imgs)\n",
    "\n",
    "            # Retrieves the index of Maximum probability for each vector of predictions\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "\n",
    "            # Updates the running total of samples and correct predictions\n",
    "            total += labels.shape[0]\n",
    "            correct += int((predicted == labels).sum())\n",
    "\n",
    "        # Calculate and prints the accuracy for the current dataset\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d445b5da-5a68-49a0-bac3-356306bd6665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Creating the Residual Block in the Neural Network\n",
    "class ResBlock(nn.Module):\n",
    "\n",
    "    # Initializing the class\n",
    "    def __init__(self, n_chans):\n",
    "        # Initializing the parent class to ensure proper setup\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        # Creating the convolution that will be applied to the input\n",
    "        self.conv = nn.Conv2d(1,n_chans,kernel_size=2,padding=1,bias=False)\n",
    "\n",
    "        # Batch normalization to normalize the activations\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "\n",
    "        # Initializing the weights of the convolutional layer with Kaiming Normal initialization\n",
    "        # This makes weights follow a normal distribution with a mean of 0,\n",
    "        # and a standard deviation that depends on the number of input units\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight, nonlinearity='relu')\n",
    "\n",
    "        # Initializing batch normalization parameters\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "\n",
    "    # Defining the forward pass of the models, which dictates how data moves through the network\n",
    "    def forward(self, x):\n",
    "        # Applies the convolutional layer to the input\n",
    "        out = self.conv(x)\n",
    "\n",
    "        # Applies the batch normalization layer to the input\n",
    "        out = self.batch_norm(out)\n",
    "\n",
    "        # Applies the ReLU activation function to introduce non-linearity\n",
    "        out = torch.relu(out)\n",
    "\n",
    "        # Adds the input to the output (residual connection)\n",
    "        # This helps to mitigate the vanishing gradient problem and allows earlier gradients\n",
    "        # to impact the output of the model\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "536dde15-9627-43c3-8242-b0c43d11adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Creating the residual model\n",
    "class ResNet(nn.Module):\n",
    "    # Initializing the variables in the class\n",
    "    def __init__(self, n_chans1=28, n_blocks=10):\n",
    "        \n",
    "        # Initializing the parent class\n",
    "        super().__init__()\n",
    "\n",
    "        # Initializes the width of each layer\n",
    "        self.n_chans1 = n_chans1\n",
    "\n",
    "        # Creating the convolution to be applied to each layer\n",
    "        self.conv = nn.Conv2d(1, n_chans1, kernel_size=1, padding=1, bias=False)\n",
    "\n",
    "        # Creating the Residual Blocks that will be stacked for the input to flow through\n",
    "        self.resblocks = nn.Sequential(\n",
    "            *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "\n",
    "        # Creating the fully connected networks to tie it all together\n",
    "        # Primarily to restrict data to feed into output (10, 0-9)\n",
    "        self.fc1 = nn.Linear(8 * 8 * self.n_chans1, 28)\n",
    "        self.fc2 = nn.Linear(28, 10)\n",
    "\n",
    "    # Creating the forward pass for how the data goes through the network\n",
    "    def forward(self, x):\n",
    "        # Applies the Functional version of MaxPool to identify structures, ReLU activation to introduce non-linearity, and runs the convolution\n",
    "        out = F.max_pool2d(torch.relu(self.conv(x)),2)\n",
    "\n",
    "        # Sends the data through the ResBlocks\n",
    "        out = self.resblocks(out)\n",
    "\n",
    "        # Applies the max pool to identify further structures in the image\n",
    "        out = F.max_pool2d(out, 2)\n",
    "\n",
    "        # Flattens out the network from 2d to 1d as fully connected networks require 1d\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "\n",
    "        # Starts sending the data through the finally activation function and fully connected networks\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4923c815-eede-4221-a08f-4904b649ce00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (60000, 2), 'test': (10000, 2)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = ds['train'][0]\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "647b7696-4ab8-4ef8-b61c-e9537e242e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAACzBVBJJwAO9dnp/wm8damu6Dw5dRjGf9IKw/+hkVPffCnWNJa7XVNV0Kxa1hErrNe/M2cnYqgElsAHpjkc1wlAODkV694W8c654t8M6n4TuvEctrrFw0cun3c0/lq+3AMJcDK5AyOeTkd+fPvGFn4gsvEtzF4m89tUG1ZJJjuMgUBVYN/EMKOe9YVXtK0bUtdvVs9LsZ7y4YgbIULYycZPoPc8V6lpfwh0/w7p66z8RdXj0y2z8llC4aWQ+mRn8lz9RXPfE3x1pvi46TYaPZTQadpMJghluWDSyrhQM9SMBe5Oc5NcBV7Tda1XRZJJNK1O8sXkG12tZ2iLD0JUjNQ3l9eahN517dT3MvTfNIXb16n6mq9Ff/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA90lEQVR4AWNgGMyAWUhIqK5jvdSy/9/rQe5kgTlWjs3KRiAYxHsyKfDzxYMgFiOIAALDvfwQBsO/pK8Mz97fhPLAlNDtvyBwbNv3j8jCUHbAnOy/f89yM2jPwiLJwMc4628UqgQTnPvp/0eGFAQXLg5lcO/764YuhuArf3y4IAfmfoQwlBX44e/fckkMYaiA7q6/f6dJ45IViP3zdzcuSQaGn39/OkBl4WEL4euFmLIwXDuETav6lKfAIPy1DYucRNFdUPCe9MOUE3e6CpI6FogZSEKrwbFyOIATQ5v5mkcgXV9auVGlwK4NDGRguL75b88HVDla8QBFF16ADQA8sQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6603e16a-4162-4f31-8d35-783411be29a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
